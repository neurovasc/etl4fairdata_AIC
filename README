# Description
This repository contains the code for the etl4fairdata_AIC project. 
The project aims to develop a pipeline to extract, transform, and load data from different sources 
to a FAIR genomic ecosystem. The final goal is to create the files that will enable the
deployement of a Beacon (json files for the BeaconFriendlyFormat for mongoDB) and the deployement 
of a SPARQL endpoint (rdf files of aggregate genomic data). 
The pipeline is developed using the Snakemake workflow management system.

# General Notes
 conda export --from-history > ~/Devlopment/etl4fairdata_AIC/conda/environement-etl4fair.yml
 https://www.youtube.com/watch?v=r9PWnEmz_tc
 snakemake --dag targets | dot -Tpng > dag.png

# Git pushing
git push --set-upstream origin --all

# About my input files 
QCed.VEP.AFctrls.GND.CADD.bcf 
- has positions with genotypes that are all reference like
- has samples that are not in the phenotype file
- has samples that are a merge of two samples in the phenotype file
signaled like sample1_sample2. These need to be eliminated as this is
contamination.

# TODOs
- For variants that do not have a gnomad frequency, should the frequency be set to 0 
in the rdf file or simply not included? Now it appears as "NaN"^^xsd:float
- Add logger and verbose argument for vcfaggregate3rdf.py
- Add custom check function that prevents the usage of both --limit and (--chunk or --threads)
- Maybe add function in vcfaggregate3rdf.py that checks if the number of variants
is the same in the vcf and in the final rdf -> it is also a sanity check in the snakemake pipeline
- Issue with clean up function -> I want to keep the intermediate merged file, but it is deleted. why?